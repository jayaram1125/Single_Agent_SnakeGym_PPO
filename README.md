Snake Gym implemented using Box2d and Envpool libraries

PPO(Proximal policy optimization) algorithm used to train the snake agent is adapted from OpenAI's Baselines and
https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/

Training duration : 7hrs 7min  using 1 TeslaV100 GPU and 6 CPU machine 

![output](https://github.com/jayaram1125/Single_Agent_SnakeGym_PPO/assets/16265393/c1771d22-ab67-42d4-96f2-32be2d7e8159)
![Reward_Episodes_Graph](https://github.com/jayaram1125/Single_Agent_SnakeGym_PPO/assets/16265393/2af75f7e-76bc-4cf9-9688-f0588c397030)
