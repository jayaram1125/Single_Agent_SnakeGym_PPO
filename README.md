Snake Gym implemented using Box2d and Envpool libraries

PPO(Proximal policy optimization) algorithm used to train the snake agent is adapted from OpenAI's Baselines and
https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/

Training duration : 7hrs 7min  using 1 TeslaV100 GPU and 6 CPU machine 

<p>
    <img width="400" height="400" src="https://github.com/jayaram1125/Single_Agent_SnakeGym_PPO/assets/16265393/721cdc1c-8137-408e-aa88-b5e6a85ed599" hspace="10" >
    <img width="400" height="400" src="https://github.com/jayaram1125/Single_Agent_SnakeGym_PPO/assets/16265393/19c9d899-1b85-4a53-bf96-5621391a3f5b" hspace="10" >
</p>

