Snake Gym implemented using Box2d and Envpool libraries

PPO(Proximal policy optimization) algorithm used to train the snake agent is adapted from OpenAI's Baselines and
https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/

Training duration : 7hrs 7min  using 1 TeslaV100 GPU and 6 CPU machine 


![image](https://github.com/jayaram1125/Single_Agent_SnakeGym_PPO/assets/16265393/c3d6e062-73a4-488b-8e61-7a46b18c68f2)
![output](https://github.com/jayaram1125/Single_Agent_SnakeGym_PPO/assets/16265393/c1771d22-ab67-42d4-96f2-32be2d7e8159) 

