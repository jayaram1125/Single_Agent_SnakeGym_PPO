Snake Gym implemented using Box2d and Envpool libraries

PPO(Proximal policy optimization) algorithm used to train the snake agent is adapted from OpenAI's Baselines and
https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/

Training duration : 7hrs 7min  using 1 TeslaV100 GPU and 6 CPU machine 

<img align="left" width="100" height="100" src="https://github.com/jayaram1125/Single_Agent_SnakeGym_PPO/assets/16265393/721cdc1c-8137-408e-aa88-b5e6a85ed599">
<img align="right" width="100" height="100" src="https://github.com/jayaram1125/Single_Agent_SnakeGym_PPO/assets/16265393/19c9d899-1b85-4a53-bf96-5621391a3f5b">

